{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e493a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea360413",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_tpu = False\n",
    "if use_tpu:\n",
    "  VERSION = \"20200220\" #@param [\"20200220\",\"nightly\", \"xrt==1.15.0\"]\n",
    "  !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "  !python pytorch-xla-env-setup.py --version $VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab16bc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, n_features, n_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "\n",
    "        self.model = nn.Linear(n_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ea34ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, loader, simclr_model, model, criterion, optimizer):\n",
    "    loss_epoch = 0\n",
    "    accuracy_epoch = 0\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = x.to(args.device)\n",
    "        y = y.to(args.device)\n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        predicted = output.argmax(1)\n",
    "        acc = (predicted == y).sum().item() / y.size(0)\n",
    "        accuracy_epoch += acc\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "        # if step % 100 == 0:\n",
    "        #     print(\n",
    "        #         f\"Step [{step}/{len(loader)}]\\t Loss: {loss.item()}\\t Accuracy: {acc}\"\n",
    "        #     )\n",
    "\n",
    "    return loss_epoch, accuracy_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae49c90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, loader, simclr_model, model, criterion, optimizer):\n",
    "    loss_epoch = 0\n",
    "    accuracy_epoch = 0\n",
    "    model.eval()\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        model.zero_grad()\n",
    "\n",
    "        x = x.to(args.device)\n",
    "        y = y.to(args.device)\n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        predicted = output.argmax(1)\n",
    "        acc = (predicted == y).sum().item() / y.size(0)\n",
    "        accuracy_epoch += acc\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "\n",
    "    return loss_epoch, accuracy_epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f3bc8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformsSimCLR:\n",
    "    \"\"\"\n",
    "    A stochastic data augmentation module that transforms any given data example randomly\n",
    "    resulting in two correlated views of the same example,\n",
    "    denoted x ̃i and x ̃j, which we consider as a positive pair.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size):\n",
    "        s = 1\n",
    "        color_jitter = torchvision.transforms.ColorJitter(\n",
    "            0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s\n",
    "        )\n",
    "        self.train_transform = torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.RandomResizedCrop(size=size),\n",
    "                torchvision.transforms.RandomHorizontalFlip(),  # with 0.5 probability\n",
    "                torchvision.transforms.RandomApply([color_jitter], p=0.8),\n",
    "                torchvision.transforms.RandomGrayscale(p=0.2),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.test_transform = torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.Resize(size=size),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.train_transform(x), self.train_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1daebc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "def yaml_config_hook(config_file):\n",
    "    \"\"\"\n",
    "    Custom YAML config loader, which can include other yaml files (I like using config files\n",
    "    insteaad of using argparser)\n",
    "    \"\"\"\n",
    "\n",
    "    # load yaml files in the nested 'defaults' section, which include defaults for experiments\n",
    "    with open(config_file) as f:\n",
    "        cfg = yaml.safe_load(f) or {}\n",
    "        for d in cfg.get(\"defaults\", []):\n",
    "            config_dir, cf = d.popitem()\n",
    "            cf = os.path.join(os.path.dirname(config_file), config_dir, cf + \".yaml\")\n",
    "            with open(cf) as f:\n",
    "                l = yaml.safe_load(f)\n",
    "                cfg.update(l)\n",
    "\n",
    "    if \"defaults\" in cfg.keys():\n",
    "        del cfg[\"defaults\"]\n",
    "\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44cfba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnet(name, pretrained=False):\n",
    "    resnets = {\n",
    "        \"resnet18\": torchvision.models.resnet18(pretrained=pretrained),\n",
    "        \"resnet50\": torchvision.models.resnet50(pretrained=pretrained),\n",
    "    }\n",
    "    if name not in resnets.keys():\n",
    "        raise KeyError(f\"{name} is not a valid ResNet version\")\n",
    "    return resnets[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03d42395",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLR(nn.Module):\n",
    "    \"\"\"\n",
    "    We opt for simplicity and adopt the commonly used ResNet (He et al., 2016) to obtain hi = f(x ̃i) = ResNet(x ̃i) where hi ∈ Rd is the output after the average pooling layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder, projection_dim, n_features):\n",
    "        super(SimCLR, self).__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.n_features = n_features\n",
    "\n",
    "        # Replace the fc layer with an Identity function\n",
    "        self.encoder.fc = Identity()\n",
    "\n",
    "        # We use a MLP with one hidden layer to obtain z_i = g(h_i) = W(2)σ(W(1)h_i) where σ is a ReLU non-linearity.\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(self.n_features, self.n_features, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.n_features, projection_dim, bias=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        h_i = self.encoder(x_i)\n",
    "        h_j = self.encoder(x_j)\n",
    "\n",
    "        z_i = self.projector(h_i)\n",
    "        z_j = self.projector(h_j)\n",
    "        return h_i, h_j, z_i, z_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b3a01ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LARS: Layer-wise Adaptive Rate Scaling\n",
    "Converted from TensorFlow to PyTorch\n",
    "https://github.com/google-research/simclr/blob/master/lars_optimizer.py\n",
    "\"\"\"\n",
    "\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "import re\n",
    "\n",
    "EETA_DEFAULT = 0.001\n",
    "\n",
    "\n",
    "class LARS(Optimizer):\n",
    "    \"\"\"\n",
    "    Layer-wise Adaptive Rate Scaling for large batch training.\n",
    "    Introduced by \"Large Batch Training of Convolutional Networks\" by Y. You,\n",
    "    I. Gitman, and B. Ginsburg. (https://arxiv.org/abs/1708.03888)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        params,\n",
    "        lr=required,\n",
    "        momentum=0.9,\n",
    "        use_nesterov=False,\n",
    "        weight_decay=0.0,\n",
    "        exclude_from_weight_decay=None,\n",
    "        exclude_from_layer_adaptation=None,\n",
    "        classic_momentum=True,\n",
    "        eeta=EETA_DEFAULT,\n",
    "    ):\n",
    "        \"\"\"Constructs a LARSOptimizer.\n",
    "        Args:\n",
    "        lr: A `float` for learning rate.\n",
    "        momentum: A `float` for momentum.\n",
    "        use_nesterov: A 'Boolean' for whether to use nesterov momentum.\n",
    "        weight_decay: A `float` for weight decay.\n",
    "        exclude_from_weight_decay: A list of `string` for variable screening, if\n",
    "            any of the string appears in a variable's name, the variable will be\n",
    "            excluded for computing weight decay. For example, one could specify\n",
    "            the list like ['batch_normalization', 'bias'] to exclude BN and bias\n",
    "            from weight decay.\n",
    "        exclude_from_layer_adaptation: Similar to exclude_from_weight_decay, but\n",
    "            for layer adaptation. If it is None, it will be defaulted the same as\n",
    "            exclude_from_weight_decay.\n",
    "        classic_momentum: A `boolean` for whether to use classic (or popular)\n",
    "            momentum. The learning rate is applied during momeuntum update in\n",
    "            classic momentum, but after momentum for popular momentum.\n",
    "        eeta: A `float` for scaling of learning rate when computing trust ratio.\n",
    "        name: The name for the scope.\n",
    "        \"\"\"\n",
    "\n",
    "        self.epoch = 0\n",
    "        defaults = dict(\n",
    "            lr=lr,\n",
    "            momentum=momentum,\n",
    "            use_nesterov=use_nesterov,\n",
    "            weight_decay=weight_decay,\n",
    "            exclude_from_weight_decay=exclude_from_weight_decay,\n",
    "            exclude_from_layer_adaptation=exclude_from_layer_adaptation,\n",
    "            classic_momentum=classic_momentum,\n",
    "            eeta=eeta,\n",
    "        )\n",
    "\n",
    "        super(LARS, self).__init__(params, defaults)\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.weight_decay = weight_decay\n",
    "        self.use_nesterov = use_nesterov\n",
    "        self.classic_momentum = classic_momentum\n",
    "        self.eeta = eeta\n",
    "        self.exclude_from_weight_decay = exclude_from_weight_decay\n",
    "        # exclude_from_layer_adaptation is set to exclude_from_weight_decay if the\n",
    "        # arg is None.\n",
    "        if exclude_from_layer_adaptation:\n",
    "            self.exclude_from_layer_adaptation = exclude_from_layer_adaptation\n",
    "        else:\n",
    "            self.exclude_from_layer_adaptation = exclude_from_weight_decay\n",
    "\n",
    "    def step(self, epoch=None, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        if epoch is None:\n",
    "            epoch = self.epoch\n",
    "            self.epoch += 1\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            weight_decay = group[\"weight_decay\"]\n",
    "            momentum = group[\"momentum\"]\n",
    "            eeta = group[\"eeta\"]\n",
    "            lr = group[\"lr\"]\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "\n",
    "                param = p.data\n",
    "                grad = p.grad.data\n",
    "\n",
    "                param_state = self.state[p]\n",
    "\n",
    "                # TODO: get param names\n",
    "                # if self._use_weight_decay(param_name):\n",
    "                grad += self.weight_decay * param\n",
    "\n",
    "                if self.classic_momentum:\n",
    "                    trust_ratio = 1.0\n",
    "\n",
    "                    # TODO: get param names\n",
    "                    # if self._do_layer_adaptation(param_name):\n",
    "                    w_norm = torch.norm(param)\n",
    "                    g_norm = torch.norm(grad)\n",
    "\n",
    "                    device = g_norm.get_device()\n",
    "                    trust_ratio = torch.where(\n",
    "                        w_norm.ge(0),\n",
    "                        torch.where(\n",
    "                            g_norm.ge(0),\n",
    "                            (self.eeta * w_norm / g_norm),\n",
    "                            torch.Tensor([1.0]).to(device),\n",
    "                        ),\n",
    "                        torch.Tensor([1.0]).to(device),\n",
    "                    ).item()\n",
    "\n",
    "                    scaled_lr = lr * trust_ratio\n",
    "                    if \"momentum_buffer\" not in param_state:\n",
    "                        next_v = param_state[\"momentum_buffer\"] = torch.zeros_like(\n",
    "                            p.data\n",
    "                        )\n",
    "                    else:\n",
    "                        next_v = param_state[\"momentum_buffer\"]\n",
    "\n",
    "                    next_v.mul_(momentum).add_(scaled_lr, grad)\n",
    "                    if self.use_nesterov:\n",
    "                        update = (self.momentum * next_v) + (scaled_lr * grad)\n",
    "                    else:\n",
    "                        update = next_v\n",
    "\n",
    "                    p.data.add_(-update)\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _use_weight_decay(self, param_name):\n",
    "        \"\"\"Whether to use L2 weight decay for `param_name`.\"\"\"\n",
    "        if not self.weight_decay:\n",
    "            return False\n",
    "        if self.exclude_from_weight_decay:\n",
    "            for r in self.exclude_from_weight_decay:\n",
    "                if re.search(r, param_name) is not None:\n",
    "                    return False\n",
    "        return True\n",
    "\n",
    "    def _do_layer_adaptation(self, param_name):\n",
    "        \"\"\"Whether to do layer-wise learning rate adaptation for `param_name`.\"\"\"\n",
    "        if self.exclude_from_layer_adaptation:\n",
    "            for r in self.exclude_from_layer_adaptation:\n",
    "                if re.search(r, param_name) is not None:\n",
    "                    return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebd64225",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bb9b44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"SimCLR\")\n",
    "config = yaml_config_hook(\"./config/config.yaml\")\n",
    "for k, v in config.items():\n",
    "    parser.add_argument(f\"--{k}\", default=v, type=type(v))\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "if use_tpu:\n",
    "  args.device = dev\n",
    "else:\n",
    "  args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bca948c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size = 64\n",
    "args.dataset = \"Custom\" # make sure to check this with the (pre-)trained checkpoint\n",
    "args.resnet = \"resnet50\" # make sure to check this with the (pre-)trained checkpoint\n",
    "args.model_path = \"../save1/NoD1500_R50_B64_Adam\"\n",
    "args.epoch_num = 100\n",
    "logistic_batch_size = 256\n",
    "args.logistic_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7ff0914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "dataset = ImageFolder(root='../data/PNU_x40', transform=TransformsSimCLR(size=args.image_size).test_transform)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                           batch_size=args.logistic_batch_size,\n",
    "                                           drop_last=True,\n",
    "                                           shuffle = True,\n",
    "                                           num_workers=args.workers,)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                          batch_size=args.logistic_batch_size,\n",
    "                                          drop_last=True,\n",
    "                                          shuffle = False,\n",
    "                                          num_workers=args.workers,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3dd43146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai/anaconda3/envs/main/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ai/anaconda3/envs/main/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "encoder = get_resnet(args.resnet, pretrained=False) # don't load a pre-trained model from PyTorch repo\n",
    "n_features = encoder.fc.in_features  # get dimensions of fc layer\n",
    "\n",
    "# load pre-trained model from checkpoint\n",
    "simclr_model = SimCLR(encoder, args.projection_dim, n_features)\n",
    "model_fp = os.path.join(\n",
    "    args.model_path, \"NoD1500_R50_B64_LARS_1000.tar\"\n",
    ")\n",
    "simclr_model.load_state_dict(torch.load(model_fp, map_location=args.device.type))\n",
    "simclr_model = simclr_model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f34951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logistic Regression\n",
    "n_classes = 3\n",
    "model = LogisticRegression(simclr_model.n_features, n_classes)\n",
    "model = model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36bb2e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88f38e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(loader, simclr_model, device):\n",
    "    feature_vector = []\n",
    "    labels_vector = []\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        x = x.to(device)\n",
    "\n",
    "        # get encoding\n",
    "        with torch.no_grad():\n",
    "            h, _, z, _ = simclr_model(x, x)\n",
    "\n",
    "        h = h.detach()\n",
    "\n",
    "        feature_vector.extend(h.cpu().detach().numpy())\n",
    "        labels_vector.extend(y.numpy())\n",
    "\n",
    "        if step % 20 == 0:\n",
    "            print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
    "\n",
    "    feature_vector = np.array(feature_vector)\n",
    "    labels_vector = np.array(labels_vector)\n",
    "    print(\"Features shape {}\".format(feature_vector.shape))\n",
    "    return feature_vector, labels_vector\n",
    "\n",
    "\n",
    "def get_features(context_model, train_loader, test_loader, device):\n",
    "    train_X, train_y = inference(train_loader, context_model, device)\n",
    "    test_X, test_y = inference(test_loader, context_model, device)\n",
    "    return train_X, train_y, test_X, test_y\n",
    "\n",
    "\n",
    "def create_data_loaders_from_arrays(X_train, y_train, X_test, y_test, batch_size):\n",
    "    train = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(X_train), torch.from_numpy(y_train)\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    test = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(X_test), torch.from_numpy(y_test)\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6420474a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Creating features from pre-trained context model ###\n",
      "Step [0/59]\t Computing features...\n",
      "Step [20/59]\t Computing features...\n",
      "Step [40/59]\t Computing features...\n",
      "Features shape (15104, 2048)\n",
      "Step [0/14]\t Computing features...\n",
      "Features shape (3584, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(\"### Creating features from pre-trained context model ###\")\n",
    "(train_X, train_y, test_X, test_y) = get_features(\n",
    "    simclr_model, train_loader, test_loader, args.device\n",
    ")\n",
    "\n",
    "arr_train_loader, arr_test_loader = create_data_loaders_from_arrays(\n",
    "    train_X, train_y, test_X, test_y, args.logistic_batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "635b0c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/500]\t Loss: 0.5966976694131302\t Accuracy: 0.7511917372881356\n",
      "Epoch [10/500]\t Loss: 0.35642379269761554\t Accuracy: 0.8516287076271186\n",
      "Epoch [20/500]\t Loss: 0.32885563424078085\t Accuracy: 0.8624205508474576\n",
      "Epoch [30/500]\t Loss: 0.31382374036110056\t Accuracy: 0.8687102754237288\n",
      "Epoch [40/500]\t Loss: 0.3034354892827697\t Accuracy: 0.8734772245762712\n",
      "Epoch [50/500]\t Loss: 0.29542187816005644\t Accuracy: 0.8779131355932204\n",
      "Epoch [60/500]\t Loss: 0.28884897595745024\t Accuracy: 0.8813559322033898\n",
      "Epoch [70/500]\t Loss: 0.28324936027243985\t Accuracy: 0.883540783898305\n",
      "Epoch [80/500]\t Loss: 0.27835640993158695\t Accuracy: 0.8858580508474576\n",
      "Epoch [90/500]\t Loss: 0.274002973305977\t Accuracy: 0.8884401483050848\n",
      "Epoch [100/500]\t Loss: 0.27007666987887885\t Accuracy: 0.8895656779661016\n",
      "Epoch [110/500]\t Loss: 0.26649778146865005\t Accuracy: 0.8910884533898306\n",
      "Epoch [120/500]\t Loss: 0.26320747475502854\t Accuracy: 0.892478813559322\n",
      "Epoch [130/500]\t Loss: 0.2601608894133972\t Accuracy: 0.8940677966101694\n",
      "Epoch [140/500]\t Loss: 0.257323052165872\t Accuracy: 0.895259533898305\n",
      "Epoch [150/500]\t Loss: 0.2546660569259676\t Accuracy: 0.896583686440678\n",
      "Epoch [160/500]\t Loss: 0.25216731378587626\t Accuracy: 0.897709216101695\n",
      "Epoch [170/500]\t Loss: 0.24980829378305855\t Accuracy: 0.8987685381355932\n",
      "Epoch [180/500]\t Loss: 0.24757355704145917\t Accuracy: 0.8996954449152542\n",
      "Epoch [190/500]\t Loss: 0.24545017465696498\t Accuracy: 0.9010195974576272\n",
      "Epoch [200/500]\t Loss: 0.24342716371608994\t Accuracy: 0.9019465042372882\n",
      "Epoch [210/500]\t Loss: 0.24149511805025198\t Accuracy: 0.9024761652542372\n",
      "Epoch [220/500]\t Loss: 0.23964591980990718\t Accuracy: 0.9030058262711864\n",
      "Epoch [230/500]\t Loss: 0.2378725510532573\t Accuracy: 0.9037341101694916\n",
      "Epoch [240/500]\t Loss: 0.23616884876105745\t Accuracy: 0.9045948093220338\n",
      "Epoch [250/500]\t Loss: 0.2345294055797286\t Accuracy: 0.9055879237288136\n",
      "Epoch [260/500]\t Loss: 0.23294942939685562\t Accuracy: 0.906051377118644\n",
      "Epoch [270/500]\t Loss: 0.231424667320009\t Accuracy: 0.9069120762711864\n",
      "Epoch [280/500]\t Loss: 0.2299513172800258\t Accuracy: 0.9076403601694916\n",
      "Epoch [290/500]\t Loss: 0.22852596943661319\t Accuracy: 0.9085672669491526\n",
      "Epoch [300/500]\t Loss: 0.22714555339287903\t Accuracy: 0.909427966101695\n",
      "Epoch [310/500]\t Loss: 0.22580728187399396\t Accuracy: 0.910354872881356\n",
      "Epoch [320/500]\t Loss: 0.224508626481234\t Accuracy: 0.9106859110169492\n",
      "Epoch [330/500]\t Loss: 0.22324730758949862\t Accuracy: 0.9111493644067796\n",
      "Epoch [340/500]\t Loss: 0.2220212259029938\t Accuracy: 0.9116790254237288\n",
      "Epoch [350/500]\t Loss: 0.2208284480591952\t Accuracy: 0.912208686440678\n",
      "Epoch [360/500]\t Loss: 0.21966718793925594\t Accuracy: 0.9124735169491526\n",
      "Epoch [370/500]\t Loss: 0.2185358796584404\t Accuracy: 0.9134666313559322\n",
      "Epoch [380/500]\t Loss: 0.21743296086788177\t Accuracy: 0.9140625\n",
      "Epoch [390/500]\t Loss: 0.21635707935034218\t Accuracy: 0.9145259533898306\n",
      "Epoch [400/500]\t Loss: 0.2153069270869433\t Accuracy: 0.9149231991525424\n",
      "Epoch [410/500]\t Loss: 0.21428133623074677\t Accuracy: 0.9158501059322034\n",
      "Epoch [420/500]\t Loss: 0.21327914777448623\t Accuracy: 0.9163797669491526\n",
      "Epoch [430/500]\t Loss: 0.21229935172250716\t Accuracy: 0.9167770127118644\n",
      "Epoch [440/500]\t Loss: 0.21134097899420787\t Accuracy: 0.917240466101695\n",
      "Epoch [450/500]\t Loss: 0.21040311455726624\t Accuracy: 0.9177039194915254\n",
      "Epoch [460/500]\t Loss: 0.20948491005574243\t Accuracy: 0.9182335805084746\n",
      "Epoch [470/500]\t Loss: 0.20858556966660385\t Accuracy: 0.9183659957627118\n",
      "Epoch [480/500]\t Loss: 0.20770433166269528\t Accuracy: 0.9184984110169492\n",
      "Epoch [490/500]\t Loss: 0.20684050629704687\t Accuracy: 0.9188294491525424\n",
      "[FINAL]\t Loss: 0.27553430093186243\t Accuracy: 0.8883928571428571\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(args.logistic_epochs):\n",
    "    loss_epoch, accuracy_epoch = train(args, arr_train_loader, simclr_model, model, criterion, optimizer)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "      print(f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t Accuracy: {accuracy_epoch / len(train_loader)}\")\n",
    "\n",
    "\n",
    "# final testing\n",
    "loss_epoch, accuracy_epoch = test(\n",
    "    args, arr_test_loader, simclr_model, model, criterion, optimizer\n",
    ")\n",
    "print(\n",
    "    f\"[FINAL]\\t Loss: {loss_epoch / len(test_loader)}\\t Accuracy: {accuracy_epoch / len(test_loader)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23cc868",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
